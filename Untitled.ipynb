{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a04cca-8026-4d1a-b9b8-1b0893425339",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'self_attention'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munits\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transformer\n",
      "File \u001b[1;32m~\\Downloads\\projects\\llms\\units\\transformer.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#from feed_forward import FeedForward\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mself_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiHeadAttention\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlayer_normalization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LayerNorm\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTransformer\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'self_attention'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from units.transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b9e474c-ca91-4a7f-9144-c8934d70a2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor:\n",
      "tensor([[[ 0.2725, -0.1480,  0.2478, -0.3707],\n",
      "         [ 0.3945,  1.1074,  0.9473,  0.3650],\n",
      "         [ 0.6822,  1.2001,  1.7417,  1.6067],\n",
      "         [ 1.4500,  1.7813, -0.9739, -0.1313],\n",
      "         [-1.3399, -1.2407, -0.2531,  1.2533]],\n",
      "\n",
      "        [[ 1.3482, -0.6312,  1.2006,  0.9291],\n",
      "         [-0.1615,  2.1465,  0.4642,  1.1020],\n",
      "         [-1.5547,  0.2597, -0.0178,  0.8630],\n",
      "         [-1.0068,  0.0888,  0.0767,  0.5099],\n",
      "         [ 0.8161,  1.0711,  0.1978,  0.1828]]])\n",
      "\n",
      "Output tensor after LayerNorm:\n",
      "tensor([[[ 1.0019, -0.5466,  0.9111, -1.3663],\n",
      "         [-0.9397,  1.2280,  0.7411, -1.0293],\n",
      "         [-1.5163, -0.2608,  1.0522,  0.7248],\n",
      "         [ 0.8125,  1.1056, -1.3317, -0.5864],\n",
      "         [-0.9065, -0.8113,  0.1362,  1.5816]],\n",
      "\n",
      "        [[ 0.8060, -1.7004,  0.6191,  0.2753],\n",
      "         [-1.2301,  1.4755, -0.4966,  0.2511],\n",
      "         [-1.6178,  0.4174,  0.1062,  1.0942],\n",
      "         [-1.6462,  0.3058,  0.2843,  1.0561],\n",
      "         [ 0.6433,  1.3015, -0.9532, -0.9917]]], grad_fn=<AddBackward0>)\n",
      "\n",
      "Mean of output tensor (should be close to 0):\n",
      "tensor([[ 0.0000e+00, -2.9802e-08,  1.4901e-07, -1.4901e-08,  2.9802e-08],\n",
      "        [ 1.4901e-08,  2.2352e-08,  0.0000e+00,  0.0000e+00, -2.9802e-08]],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "\n",
      "Standard deviation of output tensor (should be close to 1):\n",
      "tensor([[1.1546, 1.1546, 1.1547, 1.1547, 1.1547],\n",
      "        [1.1547, 1.1547, 1.1547, 1.1547, 1.1547]], grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 2  # Number of sequences in a batch\n",
    "context_length = 512  # Length of each sequence\n",
    "input_dimension = 512  # Embedding dimension\n",
    "\n",
    "# Instantiate the Transformer\n",
    "model = Transformer(\n",
    "    input_dimension=input_dimension,\n",
    "    output_dimension=input_dimension,  # Typically the same as input_dimension\n",
    "    num_heads=8,\n",
    "    context_length=context_length,\n",
    "    dropout_rate=0.1,\n",
    "    qkv_bias=True,\n",
    "    layer_norm_epsilon=1e-5,\n",
    "    ff_scaling_value=4\n",
    ")\n",
    "\n",
    "# Create dummy input tensor\n",
    "# Shape: (batch_size, context_length, input_dimension)\n",
    "dummy_input = torch.randn(batch_size, context_length, input_dimension)\n",
    "\n",
    "# Run the input through the model\n",
    "output = model(dummy_input)\n",
    "\n",
    "# Print output shape to confirm it's correct\n",
    "print(f\"Input shape: {dummy_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fdf51c-a1fd-4c8f-b0c2-63c73758c7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
